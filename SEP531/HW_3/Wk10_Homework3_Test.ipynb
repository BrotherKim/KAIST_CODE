{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wk10_Homework3_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrotherKim/KAIST_CODE/blob/master/SEP531/HW_3/Wk10_Homework3_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ox2-CDXSOal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b70d7ca-73c2-4d14-9ebf-596ddb8ae022"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIALwIbzkxHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46340531-dc8f-43f2-b2d5-b874fc26b155"
      },
      "source": [
        "!git clone https://github.com/BrotherKim/KAIST_CODE.git\n",
        "%cd KAIST_CODE/SEP531/HW_3/Homework3/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KAIST_CODE'...\n",
            "remote: Enumerating objects: 490, done.\u001b[K\n",
            "remote: Counting objects: 100% (490/490), done.\u001b[K\n",
            "remote: Compressing objects: 100% (293/293), done.\u001b[K\n",
            "remote: Total 490 (delta 298), reused 388 (delta 196), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (490/490), 40.39 MiB | 25.66 MiB/s, done.\n",
            "Resolving deltas: 100% (298/298), done.\n",
            "/content/KAIST_CODE/SEP531/HW_3/Homework3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_OHJNZa4OlN"
      },
      "source": [
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVESjRva-Ls1"
      },
      "source": [
        "os.sys.path.append('/content/KAIST_CODE/SEP531/HW_3/Homework3')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jz--oRm-Y8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19782472-a4a9-44b2-9e2c-2a459958c459"
      },
      "source": [
        "os.sys.path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/KAIST_CODE/SEP531/HW_3/Homework3']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbCk5Oe1DI3"
      },
      "source": [
        "import math\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from docopt import docopt\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "from nmt import Hypothesis, NMT\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict, Set, Union\n",
        "from tqdm import tqdm\n",
        "from utils import read_corpus, batch_iter\n",
        "from vocab import Vocab, VocabEntry\n",
        "\n",
        "import torch\n",
        "import torch.nn.utils\n",
        "import torch.nn as nn"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCMEQ-HS-F5W"
      },
      "source": [
        "def evaluate_ppl(model, dev_data, batch_size=32):\n",
        "    \"\"\" Evaluate perplexity on dev sentences\n",
        "    @param model (NMT): NMT Model\n",
        "    @param dev_data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
        "    @param batch_size (batch size)\n",
        "    @returns ppl (perplixty on dev sentences)\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    \n",
        "    cum_loss = 0.\n",
        "    cum_tgt_words = 0.\n",
        "    \n",
        "    # no_grad() signals backend to throw away all gradients\n",
        "    with torch.no_grad():\n",
        "        for src_sents, tgt_sents in batch_iter(dev_data, batch_size):\n",
        "            loss = -model(src_sents, tgt_sents).sum()\n",
        "            \n",
        "            cum_loss += loss.item()\n",
        "            tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents) # omitting leading '<s>'\n",
        "            cum_tgt_words += tgt_word_num_to_predict\n",
        "            \n",
        "        ppl = np.exp(cum_loss / cum_tgt_words)\n",
        "        \n",
        "    if was_training:\n",
        "        model.train()\n",
        "        \n",
        "    return ppl"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhv4c505-c-1"
      },
      "source": [
        "def compute_corpus_level_bleu_score(references: List[List[str]], hypotheses: List[Hypothesis]) -> float:\n",
        "    \"\"\" Given decoding results and reference sentences, compute corpus-level BLEU score.\n",
        "    @param references (List[List[str]]): a list of gold-standard reference target sentences\n",
        "    @param hypotheses (List[Hypothesis]): a list of hypotheses, one for each reference\n",
        "    @returns bleu_score: corpus-level BLEU score\n",
        "    \"\"\"\n",
        "    if references[0][0] == '<s>':\n",
        "        references = [ref[1:-1] for ref in references]\n",
        "    bleu_score = corpus_bleu([[ref] for ref in references],\n",
        "                             [hyp.value for hyp in hypotheses])\n",
        "    return bleu_score"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFiAKbEK8ckm"
      },
      "source": [
        "def decode(args: Dict[str, str]):\n",
        "    \"\"\" Performs decoding on a test set, and save the best-scoring decoding results.\n",
        "    If the target gold-standard sentences are given, the function also computes\n",
        "    corpus-level BLEU score.\n",
        "    @param args (Dict): args from cmd line\n",
        "    \"\"\"\n",
        "    \n",
        "    print('load test source sentences from [{}]'.format(args['test_src']), file=sys.stderr)\n",
        "    test_data_src = read_corpus(args['test_src'], source='src')\n",
        "    if args['test_tgt']:\n",
        "        print(\"load test target sentences from [{}]\".format(args['test_tgt']), file=sys.stderr)\n",
        "        test_data_tgt = read_corpus(args['test_tgt'], source='tgt')\n",
        "        \n",
        "    print(\"load model from {}\".format(args['model_path']), file=sys.stderr)\n",
        "    model = NMT.load(args['model_path'])\n",
        "    \n",
        "    if args['cuda']:\n",
        "        model = model.to(torch.device(\"cuda\"))\n",
        "    \n",
        "    hypotheses = beam_search(model, test_data_src,\n",
        "                             beam_size=int(args['beam_size']),\n",
        "                             max_decoding_time_step=int(args['max_decoding_time_step']))\n",
        "    \n",
        "    if args['test_tgt']:\n",
        "        top_hypotheses = [hyps[0] for hyps in hypotheses]\n",
        "        bleu_score = compute_corpus_level_bleu_score(test_data_tgt, top_hypotheses)\n",
        "        print('Corpus BLEU: {}'.format(bleu_score * 100), file=sys.stderr)\n",
        "        \n",
        "    if not os.path.exists(args['output_dir']):\n",
        "      os.makedirs(args['output_dir'])\n",
        "\n",
        "    with open(os.path.join(args['output_dir'], args['output_file']), 'w') as f:\n",
        "        for src_sent, hyps in zip(test_data_src, hypotheses):\n",
        "            top_hyp = hyps[0]\n",
        "            hyp_sent = ' '.join(top_hyp.value)\n",
        "            f.write(hyp_sent + '\\n')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwFfrVYo8dXk"
      },
      "source": [
        "def beam_search(model: NMT, test_data_src: List[List[str]], beam_size: int, max_decoding_time_step: int) -> List[List[Hypothesis]]:\n",
        "    \"\"\" Run beam search to construct hypotheses for a list of src-language sentences.\n",
        "    @param model (NMT): NMT Model\n",
        "    @param test_data_src (List[List[str]]): List of sentences (words) in source language, from test set.\n",
        "    @param beam_size (int): beam_size (# of hypotheses to hold for a translation at every step)\n",
        "    @param max_decoding_time_step (int): maximum sentence length that Beam search can produce\n",
        "    @returns hypotheses (List[List[Hypothesis]]): List of Hypothesis translations for every source sentence.\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    \n",
        "    hypotheses = []\n",
        "    with torch.no_grad():\n",
        "        for src_sent in tqdm(test_data_src, desc='Decoding', file=sys.stdout):\n",
        "            example_hyps = model.beam_search(src_sent, beam_size=beam_size, max_decoding_time_step=max_decoding_time_step)\n",
        "            \n",
        "            hypotheses.append(example_hyps)\n",
        "            \n",
        "    if was_training: model.train(was_training)\n",
        "        \n",
        "    return hypotheses"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4SrHzGI-lUU"
      },
      "source": [
        "args = dict()\n",
        "\n",
        "args['train_src'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/train.de-en.de.wmixerprep\"\n",
        "args['train_tgt'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/train.de-en.en.wmixerprep\"\n",
        "args['dev_src'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/valid.de-en.de\"\n",
        "args['dev_tgt'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/valid.de-en.en\"\n",
        "args['test_src'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de'\n",
        "args['test_tgt'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en'\n",
        "args['vocab'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/vocab.json\"\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/1_model.bin\"\n",
        "args['output_dir'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/output_dir'\n",
        "\n",
        "args['output_file'] = 'output.txt'\n",
        "args['seed'] = 0\n",
        "args['batch_size'] = 32\n",
        "args['embed_size'] = 256\n",
        "args['hidden_size'] = 256\n",
        "args['clip_grad'] = 5.0\n",
        "args['log_every'] = 10\n",
        "args['max_epoch'] = 30\n",
        "args['patience'] = 5\n",
        "args['max_num_trial'] = 5\n",
        "args['lr_decay'] = 0.5\n",
        "args['beam_size'] = 5\n",
        "args['lr'] = 0.001\n",
        "args['uniform_init'] = 0.1\n",
        "args['save_to'] = '/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp'\n",
        "args['valid_niter'] = 100\n",
        "args['dropout'] = 0.3\n",
        "args['max_decoding_time_step'] = 70\n",
        "args['cuda'] = True"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQbdFeC_Gb5S"
      },
      "source": [
        "# seed the random number generators\n",
        "seed = int(args['seed'])\n",
        "torch.manual_seed(seed)\n",
        "if args['cuda']:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed * 13 // 7)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfXPFXPZ7QQ1",
        "outputId": "10b7d404-441f-488f-f3c8-84921c18d316"
      },
      "source": [
        "# 1\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/1_model.bin\"\n",
        "decode(args)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test source sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de]\n",
            "load test target sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en]\n",
            "load model from /content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/1_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load\n",
            "Decoding:   0%|          | 0/6750 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/KAIST_CODE/SEP531/HW_3/Homework3/nmt.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding: 100%|██████████| 6750/6750 [03:34<00:00, 31.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Corpus BLEU: 28.10728656587649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEIuIiUy5qvx",
        "outputId": "7373044e-43aa-405b-b6dc-f0d54cb23964"
      },
      "source": [
        "# 3\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/3_model.bin\"\n",
        "decode(args)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test source sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de]\n",
            "load test target sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en]\n",
            "load model from /content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load\n",
            "Decoding:   0%|          | 0/6750 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/KAIST_CODE/SEP531/HW_3/Homework3/nmt.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding: 100%|██████████| 6750/6750 [03:33<00:00, 31.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Corpus BLEU: 28.197079833643873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h4f70Y07SCA",
        "outputId": "59298c29-7f43-4c8d-d55e-28d769402c3c"
      },
      "source": [
        "# 5\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/5_model.bin\"\n",
        "decode(args)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test source sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de]\n",
            "load test target sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en]\n",
            "load model from /content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/5_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load\n",
            "Decoding:   0%|          | 0/6750 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/KAIST_CODE/SEP531/HW_3/Homework3/nmt.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding: 100%|██████████| 6750/6750 [03:34<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Corpus BLEU: 28.184889877917573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Subu5hRO7WnS"
      },
      "source": [
        "# 7\n",
        "decode(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERtZMlA7YPa"
      },
      "source": [
        "# 9\n",
        "decode(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDma29Ja8VK9",
        "outputId": "643b9bca-d32b-4916-ae1e-be4dfffc694a"
      },
      "source": [
        "# 15\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/15_model.bin\"\n",
        "decode(args)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test source sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de]\n",
            "load test target sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en]\n",
            "load model from /content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/15_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load\n",
            "Decoding:   0%|          | 0/6750 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/KAIST_CODE/SEP531/HW_3/Homework3/nmt.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding: 100%|██████████| 6750/6750 [03:39<00:00, 30.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Corpus BLEU: 28.155140509930888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfs6CtVul9Pt"
      },
      "source": [
        "args = dict()\n",
        "\n",
        "args['train_src'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/train.de-en.de.wmixerprep\"\n",
        "args['train_tgt'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/train.de-en.en.wmixerprep\"\n",
        "args['dev_src'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/valid.de-en.de\"\n",
        "args['dev_tgt'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/valid.de-en.en\"\n",
        "args['test_src'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de'\n",
        "args['test_tgt'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en'\n",
        "args['vocab'] = \"/content/KAIST_CODE/SEP531/HW_3/Homework3/data/vocab.json\"\n",
        "args['model_path'] = \"/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/model.bin\"\n",
        "args['output_dir'] = '/content/KAIST_CODE/SEP531/HW_3/Homework3/output_dir'\n",
        "\n",
        "args['output_file'] = 'output.txt'\n",
        "args['seed'] = 0\n",
        "args['batch_size'] = 32\n",
        "args['embed_size'] = 256\n",
        "args['hidden_size'] = 256\n",
        "args['clip_grad'] = 5.0\n",
        "args['log_every'] = 10\n",
        "args['max_epoch'] = 30\n",
        "args['patience'] = 5\n",
        "args['max_num_trial'] = 5\n",
        "args['lr_decay'] = 0.5\n",
        "args['beam_size'] = 5\n",
        "args['lr'] = 0.001\n",
        "args['uniform_init'] = 0.1\n",
        "args['save_to'] = '/content/gdrive/MyDrive/KAIST/SEP531/hw3_cp'\n",
        "args['valid_niter'] = 100\n",
        "args['dropout'] = 0.3\n",
        "args['max_decoding_time_step'] = 70\n",
        "args['cuda'] = True"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufTuC9vAmB37",
        "outputId": "97aa1c86-8523-4e35-ebc2-1b1b56006152"
      },
      "source": [
        "decode(args)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test source sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.de]\n",
            "load test target sentences from [/content/KAIST_CODE/SEP531/HW_3/Homework3/data/test.de-en.en]\n",
            "load model from /content/gdrive/MyDrive/KAIST/SEP531/hw3_cp/model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load\n",
            "Decoding:   0%|          | 0/6750 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/KAIST_CODE/SEP531/HW_3/Homework3/nmt.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding: 100%|██████████| 6750/6750 [03:34<00:00, 31.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Corpus BLEU: 28.184889877917573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBhWQUUtmCiC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyNnvzKpHPAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}