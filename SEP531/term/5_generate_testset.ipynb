{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrotherKim/KAIST_CODE/blob/master/SEP531/term/5_generate_testset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEDjjC2Q-Znv"
      },
      "source": [
        "#변수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iQBjtGo_-ZDe"
      },
      "outputs": [],
      "source": [
        "REGION_LIST = ['ks', 'jr', 'kw', 'cc'] # jj는 특이케이스라 따로 처리\n",
        "\n",
        "ROOT_DIR = '/content/drive/MyDrive/KAIST/SEP531/kor_%s_labeled'\n",
        "TRAIN_DIR = '%s/train' % ROOT_DIR\n",
        "VALID_DIR = '%s/valid' % ROOT_DIR\n",
        "\n",
        "NUM_TRAIN = 171\n",
        "NUM_VALID = 58\n",
        "\n",
        "SAVEPOINT_PATH = '/content/drive/MyDrive/KAIST/SEP531/KoBERT_emotion_finetuned_data_std.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9TKL9NZ_Dh-"
      },
      "source": [
        "#실행 환경#\n",
        "\n",
        "- Python >= 3.6\n",
        "- PyTorch >= 1.70\n",
        "- Transformers = 3.0.2\n",
        "- Colab\n",
        "- batch size = 64 (convertable)\n",
        "- epochs = 10 (convertable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU6f6roY-5sW",
        "outputId": "61bd779a-ffac-4799-91d9-180c1165bbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.6)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595737 sha256=87e9ea93d4f252f2243363ff3a769c6927f42f9a9e2057d53747610b9305049f\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSlNTmU-_WS9"
      },
      "source": [
        "#KoBERT 다운로드#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R12JYVZJ_al4",
        "outputId": "f6f32bd7-32dd-4c95-e2ed-60bea0381ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-kdwmvqtu\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-kdwmvqtu\n",
            "Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.1.2) (0.10.0)\n",
            "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.1.2) (1.8.0.post0)\n",
            "Collecting onnxruntime>=0.3.0\n",
            "  Downloading onnxruntime-1.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.1.2) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.1.2) (1.10.0+cu111)\n",
            "Collecting transformers>=4.8.1\n",
            "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.1.2) (0.29.24)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.1.2) (21.3)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.1.2) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=0.3.0->kobert==0.1.2) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=0.3.0->kobert==0.1.2) (2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.1.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.1.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.1.2) (3.10.0.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.1.2) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.1.2) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 650 kB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.1.2) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.1.2) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.1.2) (4.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.1.2) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.1.2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime>=0.3.0->kobert==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.1.2) (7.1.2)\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=13136 sha256=2c9c1bda297695daf2f78920be00a3ec89104fc83544a8e13614b1ac0e586e43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3e3gzger/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "Successfully built kobert\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, onnxruntime, kobert\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.8.1rc1\n",
            "    Uninstalling tokenizers-0.8.1rc1:\n",
            "      Successfully uninstalled tokenizers-0.8.1rc1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 3.0.2\n",
            "    Uninstalling transformers-3.0.2:\n",
            "      Successfully uninstalled transformers-3.0.2\n",
            "Successfully installed huggingface-hub-0.2.1 kobert-0.1.2 onnxruntime-1.10.0 pyyaml-6.0 tokenizers-0.10.3 transformers-4.13.0\n"
          ]
        }
      ],
      "source": [
        "#깃허브에서 KoBERT 파일 로드\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RG56WkzA_ccN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "enK_3xLH_ecb"
      },
      "outputs": [],
      "source": [
        "#kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x35BKT7q_gAU"
      },
      "outputs": [],
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoVIALyi_hR_",
        "outputId": "565c25b4-1693-41cc-aa48-7541ab8bef99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            ".cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "#BERT 모델, Vocabulary 불러오기\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n3DFp5u_uub"
      },
      "source": [
        "#데이터셋 전처리#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsYdNv9u_wZ4",
        "outputId": "1581e20c-305b-4bff-eb7e-ea282f0ac013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#구글드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2pjNGETI-AI-"
      },
      "outputs": [],
      "source": [
        "# 터미널 커맨드를 문자열로 반환해주는 함수 작성\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def GetShellCmdStdOut(command):\n",
        "  cmd = ['sh', '-c', command]\n",
        "  fd_popen = subprocess.Popen(cmd, stdout=subprocess.PIPE).stdout \n",
        "  data = fd_popen.read().strip() \n",
        "  fd_popen.close()\n",
        "\n",
        "  retval = data.decode('utf-8') \n",
        "  return retval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def GenDataset(DIR, json_list):\n",
        "  retval = []\n",
        "\n",
        "  for fn in json_list:\n",
        "    #print('%s\\n' % (fn))\n",
        "    fd = pd.read_csv('%s/%s' % (DIR, fn), sep='\\t', header=None)\n",
        "    # [0]데이터가 표준어, [1]데이터가 사투리, [2]가 감정\n",
        "    for q, label in zip(fd[0], fd[2])  :\n",
        "      #print('%s, %s\\n' % (q, label))\n",
        "      data = []\n",
        "      data.append(q)\n",
        "      data.append(str(label))\n",
        "      retval.append(data)\n",
        "\n",
        "  return retval"
      ],
      "metadata": {
        "id": "XVuk1OSmCpbT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = []\n",
        "\n",
        "for region in REGION_LIST:\n",
        "  train_dir = TRAIN_DIR % (region)\n",
        "  print(train_dir)\n",
        "  %pushd $train_dir\n",
        "  tl = GetShellCmdStdOut('find | grep answer').split('\\n')\n",
        "  train_json_list = [x.replace('./', '') for x in tl]\n",
        "  dataset_add = GenDataset(train_dir, train_json_list)\n",
        "  #dataset_train = dataset_train + dataset_add[:11250]\n",
        "  dataset_train = dataset_train + dataset_add[45000:]\n",
        "  %popd\n",
        "\n",
        "dataset_valid = []\n",
        "\n",
        "for region in REGION_LIST:\n",
        "  valid_dir = VALID_DIR % (region)\n",
        "  print(valid_dir)\n",
        "  %pushd $valid_dir\n",
        "  vl = GetShellCmdStdOut('find | grep answer').split('\\n')\n",
        "  valid_json_list = [x.replace('./', '') for x in vl]\n",
        "  dataset_add = GenDataset(valid_dir, valid_json_list)\n",
        "  #dataset_valid = dataset_valid + dataset_add[:3750]\n",
        "  dataset_valid = dataset_valid + dataset_add[15000:]\n",
        "  %popd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MmpPDUOBwh9",
        "outputId": "99284101-d80a-4af4-c7a8-2435f37bc082"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_jr_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_jr_labeled/train\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_kw_labeled/train\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_kw_labeled/train\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_cc_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_cc_labeled/train\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_ks_labeled/valid\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/valid\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_jr_labeled/valid\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_jr_labeled/valid\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_kw_labeled/valid\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_kw_labeled/valid\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_cc_labeled/valid\n",
            "/content/drive/MyDrive/KAIST/SEP531/kor_cc_labeled/valid\n",
            "/content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n",
            "popd -> /content/drive/My Drive/KAIST/SEP531/kor_ks_labeled/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7XIvV17BwAo",
        "outputId": "98db803c-a593-44be-a1d5-9051804a4c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78559\n",
            "55144\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train))\n",
        "print(len(dataset_valid))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzLmQfJhBfQe",
        "outputId": "7e7483b7-c6c3-406d-84b8-78546fbb8015"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['많이 지치긴 지치드라.', '3'],\n",
              " ['요즘도 요즘 뭐~', '4'],\n",
              " ['코로나 터지고는 헬스장 운영 안 해 가지고 한 별로 안 가고 못 가고 이랬는데', '3'],\n",
              " ['그래도 또 하면 조금 약간 스트레스 풀리더라고 그래서', '4'],\n",
              " ['-꾸준- 꾸준히 할까 생각 중이기도 하고', '4'],\n",
              " ['근데 그거 하면은 다리 알 생기고 그런 거 아니지?', '0'],\n",
              " ['아~ 그런 거 아니야 그냥 확실히 다리하고 다릿 살은 허벅지살 특히 많이 빠져.', '4'],\n",
              " ['그런 거 하면 좋드라 그러니까', '4'],\n",
              " ['하면 확실히 여자분 들은 이~ 다리 지방 많은 그~ 다리 이쪽이 많이 빠지드라 (()) 허벅지', '3'],\n",
              " ['힘이 많이 들어가서 많이 다리는 조금 빠지는 거 같', '3']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('std_test.csv', 'w') as f:\n",
        "  for d, l in dataset_train:\n",
        "    f.write('%s, %s' % (d, l))\n",
        "  for d, l in dataset_valid:\n",
        "    f.write('%s, %s' % (d, l))"
      ],
      "metadata": {
        "id": "j-i-ydcqIJ4b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp std_test.csv /content/drive/MyDrive/KAIST/SEP531"
      ],
      "metadata": {
        "id": "v1JxSQBLInc6"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SEP531/term/5_generate_testset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVKmINuW+SKhjUmBzbxPE0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}